{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc374c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.8.0.76-cp37-abi3-macosx_11_0_arm64.whl (33.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in ./opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.25.0)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.0.76\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ac34d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "original_images_folder = \"/Users/atharva/Desktop/Master_data\"\n",
    "annotations_folder = \"/Users/atharva/Desktop/Master_data\"\n",
    "output_folder = \"/Users/atharva/Desktop/Patched_master_data\"\n",
    "\n",
    "# Define patch size\n",
    "patch_size = 160\n",
    "\n",
    "# Get a list of image files\n",
    "image_files = [f for f in os.listdir(original_images_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Create output folder if not exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through each image file\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(original_images_folder, image_file)\n",
    "    annotation_path = os.path.join(annotations_folder, os.path.splitext(image_file)[0] + \".txt\")\n",
    "\n",
    "    # Load the original image\n",
    "    original_image = Image.open(image_path)\n",
    "    image_width, image_height = original_image.size\n",
    "\n",
    "    # Load annotations from the YOLO format\n",
    "    annotations = []\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        for line in f:\n",
    "            annotations.append(list(map(float, line.strip().split())))\n",
    "\n",
    "    num_patches_x = image_width // patch_size\n",
    "    num_patches_y = image_height // patch_size\n",
    "\n",
    "\n",
    "# Loop through each patch\n",
    "    for y in range(num_patches_y):\n",
    "        for x in range(num_patches_x):\n",
    "            left = x * patch_size\n",
    "            upper = y * patch_size\n",
    "            right = left + patch_size\n",
    "            lower = upper + patch_size\n",
    "\n",
    "            # Crop the patch\n",
    "            patch = original_image.crop((left, upper, right, lower))\n",
    "\n",
    "            # Save the patch\n",
    "            patch_filename = f\"{os.path.splitext(image_file)[0]}_patch_{x}_{y}.jpg\"\n",
    "            patch.save(os.path.join(output_folder, patch_filename))\n",
    "\n",
    "            # Convert annotations for the patch\n",
    "            patch_annotations = []\n",
    "            for annotation in annotations:\n",
    "                ann_class, ann_x, ann_y, ann_w, ann_h = annotation\n",
    "\n",
    "                # Calculate annotation's boundaries\n",
    "                ann_left = ann_x - ann_w / 2\n",
    "                ann_right = ann_x + ann_w / 2\n",
    "                ann_upper = ann_y + ann_h / 2\n",
    "                ann_lower = ann_y - ann_h / 2\n",
    "\n",
    "                # Check if annotation is within the boundaries of the patch\n",
    "                if (left/640 <= ann_x <= right/640 and upper/640 <= ann_y <= lower/640) and \\\n",
    "                   (left/640 <= ann_left <= right/640 and upper/640 <= ann_upper <= lower/640) and \\\n",
    "                   (left/640 <= ann_right <= right/640 and upper/640 <= ann_lower <= lower/640):\n",
    "                    ann_x_rel = (ann_x - left/640)*4\n",
    "                    ann_y_rel = (ann_y - upper/640)*4\n",
    "                    ann_w_rel = ann_w *4\n",
    "                    ann_h_rel = ann_h *4\n",
    "                    patch_annotations.append(f\"{0} {ann_x_rel:.6f} {ann_y_rel:.6f} {ann_w_rel:.6f} {ann_h_rel:.6f}\")\n",
    "#             print(\"-------------------\")\n",
    "#             print(patch_annotations)\n",
    "#             print(\"-------------------\")\n",
    "\n",
    "            #Save annotations for the patch if there are any\n",
    "            if patch_annotations:\n",
    "                with open(os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_patch_{x}_{y}_.txt\"), 'w') as patch_ann_file:\n",
    "                    patch_ann_file.write('\\n'.join(patch_annotations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e70d553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def parse_yolo_annotation(annotation_path):\n",
    "    with open(annotation_path, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "    \n",
    "    annotations = []\n",
    "    for line in lines:\n",
    "        values = line.split()\n",
    "        class_id = int(values[0])\n",
    "        x_center, y_center, width, height = map(float, values[1:])\n",
    "        annotations.append((class_id, x_center, y_center, width, height))\n",
    "    \n",
    "    return annotations\n",
    "def draw_boxes_on_image(image_path, annotations, class_names):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        class_id, x_center, y_center, bbox_width, bbox_height = annotation\n",
    "        left = int((x_center - bbox_width / 2) * width)\n",
    "        top = int((y_center - bbox_height / 2) * height)\n",
    "        right = int((x_center + bbox_width / 2) * width)\n",
    "        bottom = int((y_center + bbox_height / 2) * height)\n",
    "        \n",
    "#         label = class_names[class_id]\n",
    "        \n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.putText(image, '.', (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99180fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = '/Users/atharva/Desktop/Patched_master_data/consep_10_patch_1_2_.txt'\n",
    "image_path = '/Users/atharva/Desktop/Patched_master_data/consep_10_patch_1_2.jpg'\n",
    "\n",
    "annotations = parse_yolo_annotation(annotation_path)\n",
    "class_names = ['']\n",
    "annotated_image = draw_boxes_on_image(image_path, annotations, class_names)\n",
    "\n",
    "cv2.imshow('Annotated Image', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477673e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
